{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1437, 64), (360, 64), (1437,), (360,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_digits()\n",
    "X = dataset.data\n",
    "Y = dataset.target\n",
    "Y = np.eye(10)[Y] # one hot\n",
    "\n",
    "X_train , X_test , Y_train ,Y_test = train_test_split(X,Y,test_size=0.2)\n",
    "X_train.shape , X_test.shape , Y_train.shape , Y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "  return 1 / ( 1 + np.exp(-X) )\n",
    "\n",
    "def softmax(X):\n",
    "  return np.exp(X) / np.sum(np.exp(X))\n",
    "\n",
    "def root_mean_squared_error(Y_gt ,Y_pred):\n",
    "  return np.sqrt(np.mean((Y_gt-Y_pred)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 80\n",
    "η = 0.001\n",
    "\n",
    "D_in = X_train.shape[1]\n",
    "H1 = 128\n",
    "H2 = 32\n",
    "D_out = Y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.random.randn(D_in , H1)\n",
    "W2 = np.random.randn(H1 ,H2)\n",
    "W3 = np.random.randn(H2 ,D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1 = np.random.randn(1,H1)\n",
    "B2 = np.random.randn(1,H2)\n",
    "B3 = np.random.randn(1,D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    # train\n",
    "    \n",
    "    Y_pred = []\n",
    "    for x, y in zip(X_train, Y_train):\n",
    "\n",
    "        # forward\n",
    "        x = x.reshape(-1, 1)\n",
    "\n",
    "        # layer 1\n",
    "        net1 = x.T @ W1 + B1\n",
    "        out1 = sigmoid(net1)\n",
    "\n",
    "        # layer 2\n",
    "        net2 = out1 @ W2 + B2\n",
    "        out2 = sigmoid(net2)\n",
    "\n",
    "        # layer 3\n",
    "        net3 = out2 @ W3 + B3\n",
    "        out3 = softmax(net3)\n",
    "\n",
    "        y_pred = out3\n",
    "        Y_pred.append(y_pred.T)\n",
    "\n",
    "        # back propagation\n",
    "\n",
    "        # layer 3\n",
    "        error = -2 * (y - y_pred)\n",
    "        grad_W3 = out2.T @ error\n",
    "        grad_B3 = error\n",
    "\n",
    "        # layer 2\n",
    "        error = error @ W3.T * out2 * (1 - out2)\n",
    "        grad_W2 = out1.T @ error\n",
    "        grad_B2 = error\n",
    "\n",
    "        # layer 1\n",
    "        error = error @ W2.T * out1 * (1 - out1)\n",
    "        grad_W1 = x @ error\n",
    "        grad_B1 = error\n",
    "\n",
    "        # update\n",
    "\n",
    "        # layer 1\n",
    "        W1 = W1 - η * grad_W1\n",
    "        B1 = B1 - η * grad_B1\n",
    "        \n",
    "        # layer 2\n",
    "        W2 = W2 - η * grad_W2\n",
    "        B2 = B2 - η * grad_B2\n",
    "\n",
    "        # layer 3\n",
    "        W3 = W3 - η * grad_W3\n",
    "        B3 = B3 - η * grad_B3\n",
    "\n",
    "    Y_pred = np.array(Y_pred).reshape(-1, 10)\n",
    "    loss_train = root_mean_squared_error(Y_pred, Y_train)\n",
    "    acc_train = np.mean(np.argmax(Y_pred, axis=1) == np.argmax(Y_train, axis=1))\n",
    "    \n",
    "    # test\n",
    "\n",
    "    Y_pred = []\n",
    "    for x, y in zip(X_test, Y_test):\n",
    "\n",
    "        # forward\n",
    "        x = x.reshape(-1, 1)\n",
    "\n",
    "        # layer 1\n",
    "        net1 = x.T @ W1 + B1\n",
    "        out1 = sigmoid(net1)\n",
    "\n",
    "        # layer 2\n",
    "        net2 = out1 @ W2 + B2\n",
    "        out2 = sigmoid(net2)\n",
    "\n",
    "        # layer 3\n",
    "        net3 = out2 @ W3 + B3\n",
    "        out3 = softmax(net3)\n",
    "\n",
    "        y_pred = out3\n",
    "        Y_pred.append(y_pred.T)\n",
    "\n",
    "    Y_pred = np.array(Y_pred).reshape(-1, 10)\n",
    "    loss_test = root_mean_squared_error(Y_pred, Y_test)\n",
    "    acc_test = np.mean(np.argmax(Y_pred, axis=1) == np.argmax(Y_test, axis=1))\n",
    "\n",
    "    print('loss train:', loss_train, 'acc train:', acc_train)\n",
    "    print('loss test:', loss_test, 'acc test:', acc_test)\n",
    "\n",
    "print('train completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread(\"test4.png\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "image = image.reshape(64,1)\n",
    "\n",
    "x = image\n",
    "# forward\n",
    "\n",
    "# layer 1\n",
    "out1 = sigmoid(x.T @ W1 + B1)\n",
    "\n",
    "# layer 2\n",
    "out2 = sigmoid(out1 @ W2 + B2)\n",
    "\n",
    "# layer 3\n",
    "out3 = softmax(out2 @ W3 + B3)\n",
    "\n",
    "y_pred = out3\n",
    "print(np.argmax(y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
